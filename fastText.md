

```bash
# 安装 fasttext 到当前目录

# fasttext 命令帮助
$ ./fasttext
usage: fasttext <command> <args>

The commands supported by fasttext are:

  supervised              train a supervised classifier(训练有监督的分类器)
  quantize                quantize a model to reduce the memory usage(量化模型以减少内存使用量)
  test                    evaluate a supervised classifier
  predict                 predict most likely labels(预测最可能的标签)
  predict-prob            predict most likely labels with probabilities(用可能性预测最可能的标签)
  skipgram                train a skipgram model(训练一个skipgram模型)
  cbow                    train a cbow model(训练一个cbow模型)
  print-word-vectors      print word vectors given a trained model
  print-sentence-vectors  print sentence vectors given a trained model
  nn                      query for nearest neighbors(查询最近邻居)
  analogies               query for analogies(查询类比)

# 下载、解压数据
$ wget https://s3-us-west-1.amazonaws.com/fasttext-vectors/cooking.stackexchange.tar.gz
$ tar -zxvf cooking.stackexchange.tar.gz
cooking.stackexchange.id
cooking.stackexchange.txt
readme.txt
# 观察数据结构
$ head cooking.stackexchange.txt
__label__sauce __label__cheese How much does potato starch affect a cheese sauce recipe?
__label__food-safety __label__acidity Dangerous pathogens capable of growing in acidic environments
__label__cast-iron __label__stove How do I cover up the white spots on my cast iron stove?
__label__restaurant Michelin Three Star Restaurant; but if the chef is not there
__label__knife-skills __label__dicing Without knife skills, how can I quickly and accurately dice vegetables?
__label__storage-method __label__equipment __label__bread What's the purpose of a bread box?
__label__baking __label__food-safety __label__substitutions __label__peanuts how to seperate peanut oil from roasted peanuts at home?
__label__chocolate American equivalent for British chocolate terms
__label__baking __label__oven __label__convection Fan bake vs bake
__label__sauce __label__storage-lifetime __label__acidity __label__mayonnaise Regulation and balancing of readymade packed mayonnaise and other sauces
# 统计数据行数
$ wc cooking.stackexchange.txt
  15404  169582 1401900 cooking.stackexchange.txt
# 生成测试数据和验证数据
$ head -n 12404 cooking.stackexchange.txt > cooking.train
$ tail -n 3000 cooking.stackexchange.txt > cooking.valid
# 训练有监督分类器
$ ./fastText-0.1.0/fasttext supervised -input cooking.train -output model_cooking
Read 0M words
Number of words:  14543
Number of labels: 735
Progress: 100.0%  words/sec/thread: 50001  lr: 0.000000  loss: 10.196953  eta: 0h0m
$ ll model_cooking.*
-rw-rw-r-- 1 lanzhiwang lanzhiwang  6382062 10月 15 19:44 model_cooking.bin
-rw-rw-r-- 1 lanzhiwang lanzhiwang 15192790 10月 15 19:44 model_cooking.vec
# 观察生成的模型数据
$ head model_cooking.vec
8952 100
</s> -0.051781 0.62322 -0.20288 -0.45736 1.0866 0.53574 -0.20942 -0.091897 0.53042 0.63385 -0.45265 -0.069507 0.34263 0.40421 -0.56093 -0.4126 0.037524 0.30031 0.056086 -0.23286 -0.16891 0.85476 0.51955 -0.24759 -0.35314 -0.60521 0.2873 -0.36957 -0.37097 0.6936 -0.45391 0.15398 -0.42174 -0.67834 -0.93513 -0.18704 -0.23858 -0.42602 -0.1175 -0.29394 -0.13424 0.90837 0.2615 0.41218 0.43978 -0.41218 0.59362 -0.049813 -0.49046 0.70237 -0.99802 0.57068 -0.40941 0.51691 -0.39807 -0.063679 -0.32419 0.122 0.56814 0.10414 -0.31524 0.56766 0.9633 0.80041 -0.37121 -0.017415 -0.85688 0.28416 -0.13068 0.1913 -0.52062 0.48711 0.15549 -0.38085 -0.58549 -0.40145 0.57208 0.81847 0.4589 -0.16484 -0.04697 0.45571 0.89437 -0.19772 0.11445 -0.21438 -0.034031 0.25134 -0.53548 -0.29207 0.84412 0.16756 1.31 -0.57298 0.065293 -0.77687 0.054794 0.60824 -0.76423 -0.6316 
? -0.075313 0.24837 -0.054487 -0.17283 0.41413 0.2592 -0.070549 -0.070781 0.14581 0.2288 -0.2077 -0.1595 0.070007 0.11422 -0.27063 -0.15797 0.025981 0.14237 -0.018736 -0.054767 -0.10124 0.35352 0.1735 -0.060163 -0.10464 -0.22447 0.080529 -0.14676 -0.14078 0.23914 -0.18396 0.024129 -0.12656 -0.32594 -0.371 -0.079512 -0.12534 -0.11066 -0.050672 -0.13812 -0.092372 0.35751 0.062879 0.21971 0.17491 -0.16877 0.22604 -0.039978 -0.18723 0.23938 -0.3256 0.24039 -0.11418 0.20015 -0.1675 0.00085956 -0.18342 0.04192 0.19833 0.046177 -0.13989 0.22319 0.33034 0.33892 -0.16499 -0.053289 -0.32301 0.079415 -0.11107 0.045283 -0.22847 0.21376 0.053244 -0.15867 -0.25029 -0.12419 0.19182 0.27215 0.19283 0.011744 -0.032081 0.15472 0.34547 0.010328 0.021176 -0.042694 -0.045515 0.11753 -0.17036 -0.099654 0.33984 0.090067 0.48929 -0.20993 0.016937 -0.22582 0.045305 0.24182 -0.28573 -0.2953 
to 0.052944 0.26475 0.03278 -0.20207 0.40533 0.25291 -0.10781 -0.073069 0.30548 0.35099 -0.23869 0.087206 0.040268 0.22067 -0.21851 -0.099227 0.048032 0.16514 -0.082617 -0.19807 0.023609 0.32707 0.17294 -0.13206 -0.1348 -0.21226 0.10793 -0.28885 -0.14792 0.26745 -0.16535 0.076721 -0.20597 -0.24157 -0.46264 -0.024549 -0.14283 -0.17376 -0.013558 -0.017134 -0.054475 0.49525 0.1585 0.27138 0.23564 -0.12293 0.24388 -0.080856 -0.19464 0.3161 -0.41939 0.20084 -0.28974 0.20063 -0.1925 -0.0042906 -0.12387 0.059805 0.23424 0.11034 -0.10604 0.24258 0.45323 0.3468 -0.054812 0.020255 -0.35011 0.057056 0.023319 0.027352 -0.24355 0.16078 0.05134 -0.071492 -0.20266 -0.08822 0.32397 0.24725 0.25109 -0.11581 -0.041246 0.064979 0.32879 -0.15386 0.097006 -0.13119 0.048104 0.074494 -0.2263 -0.019596 0.32164 0.15471 0.55911 -0.25831 0.11311 -0.30737 -0.061932 0.27609 -0.25187 -0.24102 
a 0.013332 0.37589 -0.077255 -0.049105 0.28919 0.2438 -0.10329 -0.06633 0.31471 0.19934 -0.20629 0.13267 0.026729 0.25137 -0.13399 -0.26215 -0.12572 0.017105 0.065533 -0.016514 -0.015865 0.26912 0.33081 -0.16717 -0.22554 -0.18093 0.19797 -0.15906 -0.22682 0.18193 -0.082225 -0.014611 -0.093359 -0.16461 -0.30592 0.078891 -0.024714 -0.13772 -0.10425 -0.18354 -0.073022 0.3677 -0.02976 0.060798 0.28959 -0.12004 0.20801 0.028142 -0.13384 0.127 -0.43437 0.077075 -0.11925 0.09622 -0.070176 -0.065125 -0.08626 0.18213 0.26699 0.0098644 -0.22168 0.16518 0.42241 0.19555 -0.12799 0.11489 -0.36086 -0.0015708 -0.030491 0.029893 -0.019756 0.19859 0.13464 -0.15835 -0.036921 0.057078 0.26669 0.33488 0.15347 -0.23271 -0.0014356 0.14754 0.38901 -0.22083 0.16208 -0.13551 -0.072328 0.16045 -0.26321 -0.12487 0.32299 0.093136 0.40287 -0.24119 -0.069612 -0.26579 0.023676 0.15757 -0.25035 -0.19196 
how -0.0053177 0.028003 0.086168 -0.025764 0.059323 0.041671 0.025142 -0.082072 0.049973 0.11397 -0.059357 -0.046722 -0.036095 -0.035889 -0.028466 0.041965 0.046806 0.097705 -0.054956 -0.012454 0.0047621 0.019891 -0.04025 -0.021604 0.013019 0.021452 0.029727 -0.11562 0.036518 0.081366 -0.057126 0.0037808 -0.092466 -0.025426 -0.065086 0.026064 -0.13422 -0.015764 0.033781 0.051404 -0.052094 0.11643 0.076132 0.092067 -0.0066024 -0.055846 0.072441 -0.032789 0.0019434 0.024927 -0.060278 0.11687 -0.073479 0.027225 -0.09157 0.085695 -0.052797 0.027613 -0.026865 0.077278 -0.04543 0.027224 -0.001989 0.050721 0.039433 -0.0047795 -0.046224 -0.0093601 0.015661 -0.024902 -0.13466 0.023518 0.014343 0.024574 -0.060587 -0.0084032 0.048637 -0.040184 0.079164 0.019713 0.0044486 -0.076213 0.026853 0.037158 -0.032611 -0.0050174 0.021014 0.050374 -0.0032019 0.04555 0.069988 0.065594 0.082835 -0.045955 0.10988 0.074663 -0.020609 0.020189 -0.062227 -0.048799 
the 0.04746 0.24929 0.034422 -0.23703 0.46494 0.28492 -0.12582 -0.022647 0.23763 0.36046 -0.22112 0.031847 0.034228 0.20298 -0.27608 -0.068479 0.085223 0.17032 -0.060393 -0.23147 -0.0098238 0.38589 0.14887 -0.12198 -0.12606 -0.17769 0.058521 -0.28982 -0.11534 0.27154 -0.21246 0.10697 -0.21684 -0.28677 -0.46704 -0.025624 -0.1551 -0.20118 -0.030522 0.016584 -0.047502 0.49253 0.15846 0.31026 0.19741 -0.13524 0.257 -0.13948 -0.22889 0.40096 -0.41269 0.21012 -0.3192 0.24789 -0.20505 0.00064452 -0.15716 0.050903 0.25179 0.13864 -0.13785 0.23926 0.44394 0.39559 -0.04413 -0.03906 -0.357 0.07843 -0.008996 0.052583 -0.31907 0.14438 0.03441 -0.067542 -0.26656 -0.13592 0.27668 0.25773 0.26301 -0.036839 -0.059545 0.088591 0.34878 -0.063733 0.087642 -0.074091 0.0187 0.094872 -0.24115 -0.023062 0.33003 0.14507 0.56481 -0.2486 0.095261 -0.31278 -0.083839 0.3115 -0.28609 -0.32295 
i 0.0060682 0.34818 -0.049398 -0.13804 0.30103 0.27866 -0.082142 -0.043085 0.27975 0.17466 -0.18988 0.12419 0.014173 0.30258 -0.18093 -0.16421 -0.016453 0.029284 -0.045405 -0.13291 0.013132 0.2948 0.3078 -0.14263 -0.11053 -0.26778 0.1147 -0.1672 -0.18518 0.2048 -0.097095 -0.079357 -0.093342 -0.25096 -0.40213 0.0041721 0.010041 -0.083614 -0.090151 -0.14685 -0.0066316 0.39426 0.053022 0.19511 0.3428 -0.032636 0.12793 -0.020592 -0.24218 0.1165 -0.31987 0.069124 -0.21627 0.14638 -0.04219 -0.12283 -0.084405 0.17186 0.27554 0.06954 -0.094314 0.24977 0.41503 0.22993 -0.078799 0.061815 -0.3456 0.032278 0.0062517 0.070145 -0.14485 0.16392 0.060717 -0.099892 -0.06747 0.013072 0.27785 0.25822 0.16284 -0.14763 -0.1149 0.10436 0.31938 -0.26556 0.13868 -0.14827 0.048921 0.03239 -0.24192 -0.01802 0.3136 0.12209 0.45047 -0.27698 -0.014713 -0.33791 -0.0050258 0.1828 -0.19224 -0.21345 
in 0.0085237 0.37502 -0.1207 -0.25284 0.52305 0.32554 -0.12795 0.016179 0.3065 0.25186 -0.22798 0.075573 0.13748 0.3506 -0.25685 -0.21319 -0.0029775 0.078041 -0.016319 -0.16683 -0.016333 0.41009 0.33847 -0.14438 -0.16175 -0.35655 0.12865 -0.16027 -0.22298 0.30239 -0.17967 0.020702 -0.14791 -0.35058 -0.54343 -0.057452 -0.0025471 -0.19827 -0.080082 -0.15684 0.0010903 0.48555 0.12203 0.25791 0.37169 -0.094715 0.22766 0.00013246 -0.29713 0.34321 -0.47765 0.15343 -0.23924 0.26267 -0.086642 -0.13197 -0.12414 0.13017 0.36411 0.054736 -0.10353 0.28178 0.58931 0.35773 -0.14529 9.8501e-05 -0.45538 0.11227 -0.048705 0.088978 -0.213 0.2028 0.035638 -0.16254 -0.22001 -0.10495 0.31322 0.41383 0.22647 -0.14506 -0.11873 0.21242 0.44375 -0.21512 0.14714 -0.12032 0.032722 0.057316 -0.32666 -0.098112 0.4276 0.10581 0.63877 -0.32763 -0.013403 -0.50192 -0.024678 0.26048 -0.31562 -0.31949 
is 0.02044 0.00039778 -0.044823 -0.16769 0.32419 0.07076 -0.06175 0.04085 0.014419 0.16482 -0.070988 -0.088118 0.10066 0.013989 -0.15589 -0.033567 0.07894 0.091256 0.030269 -0.096267 -0.043749 0.23694 -0.019867 -0.013186 -0.060144 -0.087202 -0.0044666 -0.045432 -0.019242 0.14201 -0.1299 0.16476 -0.10457 -0.15828 -0.19581 -0.10587 -0.051501 -0.12512 0.014035 0.039545 -0.031714 0.15634 0.11253 0.11827 -0.017039 -0.137 0.17468 -0.056571 -0.09961 0.35321 -0.19676 0.15487 -0.086366 0.15522 -0.12949 0.018837 -0.10514 -0.1238 0.1062 0.028712 -0.034186 0.11337 0.17538 0.26014 -0.1056 -0.088167 -0.12994 0.10116 -0.073954 0.037518 -0.14802 0.049758 -0.014271 -0.05753 -0.25061 -0.20646 0.031246 0.18308 0.12495 0.080001 0.020292 0.14804 0.15056 0.093902 0.00079034 0.02815 -0.013319 0.061776 -0.08506 -0.09121 0.11476 -0.020453 0.32593 -0.036577 0.0095969 -0.1984 -0.028016 0.20513 -0.16345 -0.1937
$
# 用交互式方式预测文本
$ ./fastText-0.1.0/fasttext predict model_cooking.bin -
Which baking dish is best to bake a banana bread ?
__label__baking
Why not put knives in the dishwasher?
__label__food-safety
# 验证模型
$ ./fastText-0.1.0/fasttext test model_cooking.bin cooking.valid
N	3000
P@1	0.136
R@1	0.0587
Number of examples: 3000
$ ./fastText-0.1.0/fasttext test model_cooking.bin cooking.valid 5
N	3000
P@5	0.0677
R@5	0.146
Number of examples: 3000
$
# 输出文本的前5个标签
$ ./fastText-0.1.0/fasttext predict model_cooking.bin -
Why not put knives in the dishwasher?
__label__food-safety

$ ./fastText-0.1.0/fasttext predict model_cooking.bin - 5
Why not put knives in the dishwasher?
__label__food-safety __label__baking __label__bread __label__equipment __label__substitutions
# 以非交互式方式运行
$ cat test.txt
Which baking dish is best to bake a banana bread ?
Why not put knives in the dishwasher?
Why not put knives in the dishwasher?
$
$ ./fastText-0.1.0/fasttext predict model_cooking.bin test.txt 2
__label__bread __label__baking
__label__food-safety __label__baking
__label__food-safety __label__baking
$ 
$ ./fastText-0.1.0/fasttext print-sentence-vectors model_cooking.bin < test.txt
0.010838 0.32251 0.0018 -0.1393 0.28517 0.27495 -0.093648 -0.04564 0.26601 0.21855 -0.2035 0.11237 -0.017012 0.29593 -0.19623 -0.14209 0.0015843 0.083805 -0.075628 -0.17328 0.014877 0.28458 0.24118 -0.13538 -0.10069 -0.22493 0.08599 -0.21774 -0.16935 0.17449 -0.098764 -0.020882 -0.096189 -0.25014 -0.40864 0.0027028 -0.036393 -0.10199 -0.059659 -0.088981 -0.014554 0.41472 0.058719 0.25107 0.29597 -0.046373 0.12025 -0.057695 -0.21746 0.16724 -0.32039 0.080298 -0.24024 0.15626 -0.073412 -0.074393 -0.099186 0.12281 0.2428 0.098647 -0.093258 0.23056 0.42059 0.26877 -0.04747 0.033715 -0.29034 0.010309 0.0098754 0.042614 -0.15791 0.13986 0.041945 -0.04308 -0.081686 0.023805 0.2859 0.21611 0.1816 -0.11783 -0.11504 0.067771 0.30978 -0.21405 0.13006 -0.13892 0.055538 0.02473 -0.22285 -0.0029997 0.30365 0.15492 0.45209 -0.24925 0.028582 -0.29744 -0.028021 0.22202 -0.16367 -0.21138 
0.00145 0.2302 -0.054436 -0.1726 0.37969 0.21481 -0.087611 -0.012809 0.19813 0.23367 -0.16675 0.012125 0.090623 0.17926 -0.19973 -0.12572 0.027203 0.10004 -0.0030934 -0.12054 -0.034694 0.30578 0.18466 -0.095607 -0.11784 -0.21265 0.085819 -0.15313 -0.13374 0.23198 -0.15396 0.053445 -0.14311 -0.24253 -0.36151 -0.050234 -0.069581 -0.15213 -0.042819 -0.07861 -0.033867 0.35076 0.097889 0.17727 0.18545 -0.11779 0.19853 -0.037329 -0.19244 0.26736 -0.35118 0.16837 -0.18231 0.19112 -0.12766 -0.034289 -0.11247 0.055819 0.22002 0.058953 -0.10219 0.20163 0.37126 0.28786 -0.10206 -0.0093652 -0.30747 0.084114 -0.035765 0.061696 -0.19219 0.15265 0.039923 -0.1107 -0.19779 -0.1152 0.21593 0.27505 0.17622 -0.062677 -0.042941 0.13794 0.31159 -0.089261 0.066415 -0.074779 0.0031386 0.075679 -0.20471 -0.076418 0.29295 0.078605 0.46418 -0.21404 0.026947 -0.29467 -0.011417 0.2191 -0.25216 -0.23284 
0.00145 0.2302 -0.054436 -0.1726 0.37969 0.21481 -0.087611 -0.012809 0.19813 0.23367 -0.16675 0.012125 0.090623 0.17926 -0.19973 -0.12572 0.027203 0.10004 -0.0030934 -0.12054 -0.034694 0.30578 0.18466 -0.095607 -0.11784 -0.21265 0.085819 -0.15313 -0.13374 0.23198 -0.15396 0.053445 -0.14311 -0.24253 -0.36151 -0.050234 -0.069581 -0.15213 -0.042819 -0.07861 -0.033867 0.35076 0.097889 0.17727 0.18545 -0.11779 0.19853 -0.037329 -0.19244 0.26736 -0.35118 0.16837 -0.18231 0.19112 -0.12766 -0.034289 -0.11247 0.055819 0.22002 0.058953 -0.10219 0.20163 0.37126 0.28786 -0.10206 -0.0093652 -0.30747 0.084114 -0.035765 0.061696 -0.19219 0.15265 0.039923 -0.1107 -0.19779 -0.1152 0.21593 0.27505 0.17622 -0.062677 -0.042941 0.13794 0.31159 -0.089261 0.066415 -0.074779 0.0031386 0.075679 -0.20471 -0.076418 0.29295 0.078605 0.46418 -0.21404 0.026947 -0.29467 -0.011417 0.2191 -0.25216 -0.23284 
$

$
# 优化模型
$ cat cooking.stackexchange.txt | sed -e "s/\([.\!?,'/()]\)/ \1 /g" | tr "[:upper:]" "[:lower:]" > cooking.preprocessed.txt
$ head -n 12404 cooking.preprocessed.txt > cooking.train
$ tail -n 3000 cooking.preprocessed.txt > cooking.valid
$ ./fastText-0.1.0/fasttext supervised -input cooking.train -output model_cooking
Read 0M words
Number of words:  8952
Number of labels: 735
Progress: 100.0%  words/sec/thread: 52856  lr: 0.000000  loss: 10.107295  eta: 0h0m
$ ./fastText-0.1.0/fasttext test model_cooking.bin cooking.valid
N	3000
P@1	0.169
R@1	0.0732
Number of examples: 3000
$ ./fastText-0.1.0/fasttext supervised -input cooking.train -output model_cooking -epoch 25
$ ./fastText-0.1.0/fasttext supervised -input cooking.train -output model_cooking -lr 1.0
$ ./fastText-0.1.0/fasttext supervised -input cooking.train -output model_cooking -lr 1.0 -epoch 25
$ ./fastText-0.1.0/fasttext supervised -input cooking.train -output model_cooking -lr 1.0 -epoch 25 -wordNgrams 2
$ ./fastText-0.1.0/fasttext supervised -input cooking.train -output model_cooking -lr 1.0 -epoch 25 -wordNgrams 2 -bucket 200000 -dim 50 -loss hs
$

```

* [参考1](https://fasttext.cc/)

* [参考2](https://github.com/facebookresearch/fastText)